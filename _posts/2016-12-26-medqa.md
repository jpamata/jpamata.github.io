---
title: "Medical QA"
layout: post
date: 2016-12-26 22:10
tag: 
- Academic Project
projects: true
hidden: true # don't count this post in blog pagination
description: "The Question Answering (QA) task aims to provide precise and quick answers to user questions from a collection of documents or a database. This is the foundation of our study: we aim to be familiar about studying different appropriate models of Question Answering systems that will not only provide users answers in bulk, but precisely deliver answers that is expected to solve a user's question."
category: project
author: john
externalLink: false
---


<p align="center">Medical Question Answering: Revisited</p>

> Project Constituents

<h3>Project Professor</h3>
<table border="0" width="75%" align="center">		
<tr>
		<td bgcolor="#BB1DF0"><div class="center">Name</div></td>
		<td bgcolor="#BB1DF0"><div class="center">Position</div></td>
		<td bgcolor="#BB1DF0"><div class="center">E-Mail</div></td>
</tr>
<tr>
		<td bgcolor="#f68efa"><div class="center">Sir Manuel Sebastian Sanchez</div></td>
		<td bgcolor="#f68efa"><div class="center">Professor</div></td>
		<td bgcolor="#f68efa"><div class="center">manuels@apc.edu.ph</div></td>
</tr>
</table>

<h3>Project Team Members</h3>
<table border="0" width="75%" align="center">
<tr>
	<td bgcolor="#BB1DF0"><div class="center">Name</div></td>
	<td bgcolor="#BB1DF0"><div class="center">Position</div></td>
	<td bgcolor="#BB1DF0"><div class="center">E-Mail</div></td>
</tr>
<tr>
	<td bgcolor="#f68efa"><div class="center">John Patick Amata</div></td>
	<td bgcolor="#f68efa"><div class="center">Project Manager/Programmer</div></td>
	<td bgcolor="#f68efa"><div class="center">jaamata@student.apc.edu.ph</div></td>
</tr>
<tr>
	<td bgcolor="#f68efa"><div class="center">Jayvee D. Febrer</div></td>
	<td bgcolor="#f68efa"><div class="center">System Analyst/Programmer</div></td>
	<td bgcolor="#f68efa"><div class="center">jdfebrer@student.apc.edu.ph</div></td>
</tr>
<tr>
	<td bgcolor="#f68efa"><div class="center">Immanuel T. Espiritu jr.</div></td>
	<td bgcolor="#f68efa"><div class="center">System Analyst/Programmer</div></td>
	<td bgcolor="#f68efa"><div class="center">itespiritu@student.apc.edu.ph</div></td>
</tr>
			
</table>

<h3>Project Adviser</h3>
<table border="0" width="75%" align="center">
<tr>
	<td bgcolor="#BB1DF0"><div class="center">Name</div></td>
	<td bgcolor="#BB1DF0"><div class="center">Position</div></td>
	<td bgcolor="#BB1DF0"><div class="center">E-Mail</div></td>
</tr>
<tr>
	<td bgcolor="#f68efa"><div class="center">Dr. Lorena Rabago</div></td>
	<td bgcolor="#f68efa"><div class="center">Director - Quality Assurance</div></td>
	<td bgcolor="#f68efa"><div class="center">lorenar@apc.edu.ph</div></td>
</tr>
</table>


> Abstract
<p style="text-indent:50px">The Question Answering (QA) task aims to provide precise and quick answers to user questions from a collection of documents or a database. This is the foundation of our study: we aim to be familiar about studying different appropriate models of Question Answering systems that will not only provide users answers in bulk, but precisely deliver answers that is expected to solve a user's question.</p>

> List of Figures, List of Tables, List of Notations==

<h3>Event Table</h3>

<table style="border:2px solid black;" width="75%" align="center">
<tr>
	<td height="75" bgcolor="#f68efa"><div class="center">EVENT</div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">TRIGGER</div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">SOURCE</div></td>
        <td height="75" bgcolor="#f68efa"><div class="center">USE CASE</div></td>
        <td height="75" bgcolor="#f68efa"><div class="center">RESPONSE</div></td>
        <td height="75" bgcolor="#f68efa"><div class="center">DESTINATION</div></td>
</tr>
<tr>
	<td height="75" bgcolor="#fdbfff"><div class="center"><strong>User Ask a question</strong></div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">The user input a question</div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">User</div></td>
        <td height="75" bgcolor="#fdbfff"><div class="center">ASK QUESTION</div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">System processes the question</div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">SYSTEM</div></td>
</tr>
<tr>
	<td height="75" bgcolor="#f68efa"><div class="center"><strong>System receives a question entered by User</strong></div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">System receives a question</div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">User</div></td>
        <td height="75" bgcolor="#f68efa"><div class="center">QUESTION PROCESSING</div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">System analyze and parse the question</div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">SYSTEM</div></td>
</tr>
<tr>
	<td height="75" bgcolor="#fdbfff"><div class="center"><strong>System receive parsed question</strong></div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">System receives the processed question</div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">System</div></td>
        <td height="75" bgcolor="#fdbfff"><div class="center">QUERY</div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">System searches for most relevant data</div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">SYSTEM</div></td>
</tr>
<tr>
	<td height="75" bgcolor="#f68efa"><div class="center"><strong>System received processed question</strong></div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">System finished processing the question</div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">System</div></td>
        <td height="75" bgcolor="#f68efa"><div class="center">RETRIEVE</div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">System retrieve the nearest possible data and process it into an answer</div></td>
	<td height="75" bgcolor="#f68efa"><div class="center">SYSTEM</div></td>
</tr>
<tr>
	<td height="75" bgcolor="#fdbfff"><div class="center"><strong>System send back the answer to User</strong></div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">System retrieved the answer to the corpus</div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">System</div></td>
        <td height="75" bgcolor="#fdbfff"><div class="center">ANSWER</div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">System sends the process data as an answer</div></td>
	<td height="75" bgcolor="#fdbfff"><div class="center">USER</div></td>
</tr>

</table>


> I.  Introduction

<h3>Background of the Problem</h3>
<p style="text-indent:50px">The medical profession requires a great deal of memorization and information retrieval of medical texts. Doctors and physicians often need to refer to medical documents and most get theirs from the internet. Due to their profession, time is of great essence. A study showed that it took an average of more than 30 minutes for a healthcare provider to search for answers from PubMed.</p>
<p style="text-indent:50px">The problem lies on the cause of information overloading; a simple query immediately presents hundreds of articles. Question answering systems provide answers for questions in a natural language form.  They accomplish this task by analysing the text and providing a summarised answer from a database of articles and documents. An early feasibility study on Medical Question Answering systems showed that In QA as in IR, one cannot search for every kind of information on the internet, since they are not equally represented.  Due to the promising value that Medical Q&A systems bring, our aim is to study the modern trends of information retrieval and question answering models and their application to the Medical field.
</p>

<h3>Statement of the Problem</h3>
<p>What are the impact of modern advancements in QA in making a Medical Question Answering system? 
</p>

<h3>Objectives</h3>
<p>Our objective is to experiment and study applicable trends in Question Answering and its application to a Medical Question Answering system.
</p>

<h3>Significance</h3>
<p style="text-indent:50px">Our study will provide a modern model(s) of a question answering system for researchers and developers to follow in creating their own Medical Question Answering system. The promising value that Medical Q&A systems bring in regards to the summarising texts and answering in quick manner, addresses the problem of information overload that medicine practitioners encounter.
</p>

<h3>Scope and Limitation</h3>
<p style="text-indent:50px">Our study will only examine and experiment with Factoid Question Answering systems. For the context of our corpus, we shall gather at least 50 questions about Diabetes. With these serving as our usage context, we shall apply information retrieval methods for the first release of our system. 
</p>

<h2>Scope of Initial Release</h2>
<p style="text-indent:50px">The Initial Release of our product is slated for December 18, 2016. The initial release shall only cover the most important functions and features to serve as a proof of concept. It will be used to gather validated learning and insights for the continued development towards the final product. It shall also serve as a form of market analysis in the field of QA.
</p>

<h3>This Release (1.0) will include:</h3>
<li>Question Classification: The first stage, this determines the type of answer that shall be provided.</li>
<li>Text Selection: This module typically uses several components that apply increasingly complex NLP techniques on a gradually reduced amount of text. The focus of this stage is to identify the documents or paragraphs in the document set that are likely to contain the answer, and a filter preselects small text fragments that contain strings of the same type as the expected answer.</li>
<li>Answer Construction: This module expands on previous stage -- text selection -- by looking for further clues in the text to determine if the candidate answer can indeed answer the question.</li><br>

<h3>The next release (1.1) may/not include:</h3>
<li>Neural Network Integration for Question Classification</li>
<li>Basic Intelligent Expert System</li>
<li>Expanded Corpus for Expert System</li>

> II. Review on Related Literature

<h3>Stanford CoreNLP</h3>
<p style="text-indent:50px">It provides a set of natural language analysis tools. It can give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize dates, times, and numeric quantities, and mark up the structure of sentences in terms of phrases and word dependencies, indicate which noun phrases refer to the same entities, indicate sentiment, extract open-class relations between mentions, etc.</p>

<h3>Apache UIMA</h3>
<p style="text-indent:50px">UIMA is a component software architecture for the development, discovery, composition, and deployment of multi-modal analytics for the analysis of unstructured information and its integration with search technologies developed by IBM. The source code for a reference implementation of this framework has been made available on SourceForge, and later on the website of the Apache Software Foundation.</p>

<h3>Apache Solr</h3>
<p style="text-indent:50px">Solr is highly reliable, scalable and fault tolerant, providing distributed indexing, replication and load-balanced querying, automated failover and recovery, centralized configuration and more. Solr powers the search and navigation features of many of the world's largest internet sites.</p>

<h3>Apache Lucene</h3>
<p style="text-indent:50px">Apache LuceneTM is a high-performance, full-featured text search engine library written entirely in Java. It is a technology suitable for nearly any application that requires full-text search, especially cross-platform.</p>

<h3>Apache OpenNLP</h3>
<p style="text-indent:50px">The Apache OpenNLP library is a machine learning based toolkit for the processing of natural language text.

It supports the most common NLP tasks, such as tokenization, sentence segmentation, part-of-speech tagging, named entity extraction, chunking, parsing, and coreference resolution. These tasks are usually required to build more advanced text processing services. OpenNLP also includes maximum entropy and perceptron based machine learning.
</p>

<h3>LingPipe</h3>
<p style="text-indent:50px">
LingPipe is tool kit for processing text using computational linguistics. LingPipe is used to do tasks like:</p>
<ul>
<li>Find the names of people, organizations or locations in news</li>
<li>Automatically classify Twitter search results into categories</li>
<li>Suggest correct spellings of queries</li>
</ul>

<h3>Natural Language Toolkit</h3>
<p style="text-indent:50px">The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP). It contains text processing libraries for tokenization, parsing, classification, stemming, tagging and semantic reasoning.</p>

<h3>Elasticsearch</h3>
<p style="text-indent:50px">Elasticsearch is a search server based on Lucene. It provides a distributed, multitenant-capable full-text search engine with a RESTful web interface and schema-free JSON documents. Elasticsearch is developed in Java and is released as open source under the terms of the Apache License.</p>

<h3>NlpTools</h3>
<p style="text-indent:50px">NlpTools is a library for natural language processing written in php.</p>

<h3>Question Answering</h3>
<p style="text-indent:50px">From a very general perspective QA can be defined as an automatic process capable of understanding questions formulated in a natural language such as English and responding exactly with the requested information.
</p>

<h3>AUTOMATED QUESTION-ANSWERING TECHNIQUES AND THE MEDICAL DOMAIN </h3>
<p style="text-indent:50px"> This paper discusses which of three major QA approaches, i.e. deep Natural Language Processing(NLP), Information Retrieval (IR) enhanced byshallow NLP, and Template-based QA, better fit medical applications, eliciting their context of pertinence. To our knowledge, this is the first formalcomparison of the three QA approaches that focuseson the medical domain.  

A common feature of deep NLP systems is that they convert text input into formal representation of
meaning such as logic (first order predicate calculus), semantic networks, conceptual dependency diagrams, or frame-based
representations (Jurafsky and Martin, 2000, p. 502). In other words deep NLP systems perform a semantic analysis of text in NL. Semantic analysis is the process of studying the meaning of a linguistic input and giving a formal representation of it. Jurafsky and Martin (2000, p. 548) provide a possible approach for semantic analysis (see figure 1 on the next page): the user input is first passed through a syntactic parser, whose output, represented with a parse tree, is then processed by asemantic analyzer which delivers a meaning representation. 

</p>

<h3>New Trends in Automatic Question Answering</h3>
<p style="text-indent:50px">The following paper focuses on Automatic Question Answering (Automatic QA), a sub- field of Information Retrieval. The first chapters focus on historical developments and the definition of the field. Thereafter, an overview of current research topics and key aspects will be given, as well as a classification of the most interesting approaches. The main part of this paper is an analysis of new trends regarding Automatic QA, primarily focusing on approaches in association with web and new media technologies. A discussion of available tools will follow up. Finally, a summary of the things learned during the research on the topic will conclude this work.
In the beginning of Automatic Q&A the studies where in a shape of creating an intelligent computer system, which can interact with a human being. It evolved from simple interaction systems without a knowledge database relying on a domain specific field to complex systems, which are web-scaling and able to answer elaborate questions in an interactive and context based way.
</p>

<p><strong>Structure of the Work</strong></p>
<p style="text-indent:50px">This paper focus on new trends in Automatic QA. The Automatic QA Process can be divided into 4 major parts: Question Analysing, Preparing the Dataset, Text Processing and Data Mapping.<br>
<br>
The Information Retrieval part in the Automatic QA project takes care of finding documents, which contain useful information for the question answering. As it was common in the previous years that in Automatic Q&A only document retrieval was used, the information retrieval approach nowadays can also deliver text passages where valuable information can be extracted.<br>
<br>
The <strong>Natural Language Processing</strong> approach performs a semantic analysis of text. It therefore uses machine learning algorithms to learn rules for text analysis. It uses sets of theories and technologies. In the early years the most common algorithms were decision trees, the latest approaches base on statistical model and probalistic decisions.(Gunawardena, Lokuhetti, Pathirana, Ragel & Deegalla, 2010)<br>
<br>
The first kind of Automatic QA system is so called ELIZA. The system relies on natural language processing and formed a question out of a statement by using simple pattern matching. It worked on a MAC time-sharing system at MIT. The program could run different scripts to simulate a human conversation partner.
</p>

<p><strong>Computational Linguistic</strong></p>

<table border="1" width="75%" align="center">
<tr>
    <td>Maximum Entropy Model</td>
    <td>The basic idea of the maximum entropy model is, that the probability distribution which best represents the current state of knowledge is the one with the largest entropy. It is used to build up models of many different sources with limited information.</td>
</tr>
<tr>
    <td>Decision Tree Learning</td>
    <td>Decision tree learning is a method used in many domains of knowledge discovery, pattern recognition and data mining. Decision trees are hierarchical trees which try to predict an output variable for a given input. Each leave represents an attribute. Each path is a conjunction of the attributes which are on the path.</td>
</tr>
<tr>
    <td>Artificial Neural Networks</td>
    <td>Artificial neural networks are mathematical models based on the biological neuron structure of the brain. The neurons, also called nodes, together with the weighted connections are the basic components. The advantages of artificial neural networks are the possibility of enhancing the processing speed by parallelization, adaptation of knowledge, robustness and implementation in low power applications.</td>
</tr>
</table>

<p><strong>Information Extraction</strong></p>
<table border="1" width="75%" align="center">
<tr>
    <td>Entity extraction</td>
    <td>It identifies and classifies all phrases in a free text which refer to objects of semantic classes like names, nouns, pronouns etc. In addition all object mentions are linked together which refer to the same entity.</td>
</tr>
<tr>
    <td>Relation extraction</td>
    <td>The relations between entities are identified. A relation is always represented by two entities and can be described in many languages. </td>
</tr>
<tr>
    <td>Event extraction</td>
    <td>It is also a common application in order to derive specific knowledge from a text. Event extraction identifies events of particular types and the corresponding arguments. A type of an event would be for example ”car crash” or ”natural disaster”.</td>
</tr>
</table>

<h3>Architecture of an Ontology-Based Domain-Specific Natural Language Question Answering System</h3>
<p style="text-indent:50px">The proposed architecture of an ontology-based domain-specific NLQA system is depicted in Figure 2. The model integrates key components such as Natural Language Processing techniques; Conceptual Indexing based Retrieval Mechanism, and Ontology Processing.
</p>

<br><center> <img src="http://i.imgur.com/AZHJruU.jpg"> </center><br>

<p><strong>Question Processing</strong></p>
<p style="text-indent:50px">In the question processing module, with the help of various components, the following actions are performed.
· Analysis of the natural language question
· Question classification
· Reformulation of the user query
</p>

<p><strong>Query Analyzer</strong></p>
<p style="text-indent:50px">The natural-language question given by the user is analyzed using various natural language processing techniques.
<br> Syntactic Analysis – The question is analyzed syntactically using NLP techniques. Part-ofspeech tagging and named entity recognition (NER) are performed. Tools such as Pythonnltk, OpenNLP, Stanford CoreNLP can be used for this purpose. In the proposed system, we used Stanford CoreNLP tool-kit. The CoreNLP processes the document and creates an XML file as output. Shallow parsing is performed to identify the phrasal chunks. The phrasal chunks can be identified using the Regular-expression chunker and the Conll-2000 trained chunker.
<br> Semantic Analysis - Semantic role labeling is an important step in this module, which enables to find the dependencies or restriction that, can be imposed, after getting the user query . This greatly eliminates the chances of irrelevant set of answers. Semantic roles are identified using the verbnet frames.
</p>

<p><strong>Question Classification</strong></p>
<table border="1" width="75%" align="center">
<tr>
     <td><strong>Question Word</strong></td>
     <td><strong>Function</strong></td>
     <td><strong>Question Focus</strong></td>
</tr>
<tr>
     <td>Who</td>
     <td>Asking what or which person or people(subject)</td>
     <td>PERSON</td>
</tr>
<tr>
     <td>Whom</td>
     <td>Asking what or which person or people(object)</td>
     <td>PERSON</td>
</tr>
<tr>
     <td>Whose</td>
     <td>Asking about ownership</td>
     <td>PERSON</td>
</tr>
<tr>
     <td>Where</td>
     <td>Asking in or at what place or position</td>
     <td>LOCATION</td>
</tr>
</table>

<p><strong>Query Reformulation</strong></p>
<p style="text-indent:50px">The user queries may be reformulated by adding domain knowledge and ontological information.
</p>

<p><strong>Document Retrieval</strong></p>
<p style="text-indent:50px">This module selects a set of relevant documents from a domain specific repository. Conceptual indexing is used for the retrieval process since the key word based indexing ignores the semantic content of the document collection. Both the documents and queries can be mapped into concepts and these concepts are used as a conceptual indexing space for identifying and extracting documents.
</p>

<p><strong>Document Processing</strong></p>
<p style="text-indent:50px">The retrieved documents are processed for extracting candidate answer set. This module is responsible for selecting the response based on the relevant fragments of the documents.
</p>
<table border="1" width="75%" align="center">
<tr>
     <td>Syntactic Analysis</td>
     <td>The documents analyzed syntactically using the NLP techniques such as part-of-speech tagging and named-entity recognition.</td>
</tr>
<tr>
     <td>Semantic Analysis</td>
     <td>Shallow parsing can be performed for finding the semantic phrases or clauses. The semantic roles are identified and mapped to semantic frames. The sentences whose semantic frames map exactly to the semantic frames of the question are also extracted.</td>
</tr>
<tr>
     <td>Relation Identification</td>
     <td>The base ontology is populated with the domain knowledge incrementally as we go through different set of documents. By this method a valid knowledge on any specialized discipline can be incorporated to the system. The relations among different concepts are identified using the domain knowledge and the ontological information obtained.</td>
</tr>
</table>

<p><strong>Answer Extraction</strong></p>
<p style="text-indent:50px">The filtering of candidate answer set and answer generation is performed. The user is supplied with a set of short and specific answers ranked according to their relevance. The different stages are, Filtering, Answer Ranking and Answer Generation.
</p>

> III.  Technical Background
<p> A machine capable of understanding a text like we humans do? I know, it seems hard to believe, and for years it seemed like magic , 
 until I discovered Natural Language Processing (NLP), a field that deals with this kind of problems.Yes,
 by combining the power of artificial intelligence, computational linguistics and computer science, 
 NLP allows a machine to understand natural language, a task that was so far the exclusive privilege of humans.
 NLP is everywhere even if we don’t know it.  Language transaltor used in different social media sites or websites are just one example of NLP at work.
 Another example which we are focusing on is Question Answering. The Question Answering (QA) task aims to provide precise and quick answers to user questions from a collection of documents or a database.Also if we are talking about information handled by computers, we can co-relate this to a Expert system. Expert systems is a piece of software programmed using artificial intelligence techniques. Such systems use databases of expert knowledge to offer advice or make decisions in such areas as medical diagnosis and trading on the stock exchange.
 This kind of IR system is sorely needed with the dramatic growth of digital information.
 One domain that is mostly in need of this QA systems is medical domain. 
 Why ? simply because every act of knowledge and application in medicine is now worked by computers. 
 One example is an online web application called "webmd" this application serves as a portal for questioning and it gives results and information to the user. 
 There are many application that is involving medical fields in Natural language Processing. 
 IBM watson is one of the most famous artificial intelligence that uses NLP and IR (information retreival) for its main functionality of answering questions. 
 In engaging in this field of study, it is recommended to be familiar with the unimaginable number of exsisting application 
 or tools to be use (tenserflow, apache open nlp, ibm watson, etc..)</p>

<h4>Natural Language Processing</h4>

<p>

A field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. 
As such, NLP is related to the area of human–computer interaction.


</p>

<h4> Question Answering System </h4>

<p>

Question Answer (Q AND A) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.

</p>

<h4> Information Retreival </h4>

<p>

Information retrieval (IR) is the activity of obtaining information resources relevant to an information need from a collection of information resources. Searches can be based on full-text or other content-based indexing.

</p>

<h4> Expert System </h4>

<p>

A computer application that performs a task that would otherwise be performed by a human expert. For example, there are expert systems that can diagnose human illnesses, make financial forecasts, and schedule routes for delivery vehicles. Some expert systems are designed to take the place of human experts, while others are designed to aid them.
Expert systems are part of a general category of computer applications known as artificial intelligence .

</p>

<h4> Artificial Intelligence </h4>

<p>
Artificial intelligence (AI) is intelligence exhibited by machines. In computer science, an ideal "intelligent" machine is a flexible rational agent that perceives its environment and takes actions that maximize its chance of success at some goal.
</p>

> IV.  Design and Methodology
<p><strong>Components</strong></p>
<p style="text-indent:50px">The general components of a typical (mostly factoid based) Question Answering system that we will also include are the following:</p>

<p><strong>1.	Question Processing</strong></p>
<p style="text-indent:50px">Under the Question Processing lies two main processes: Question Classification and Query Generation.</p>

<li><strong>Question Classification</strong> - Question and answer types are categories in taxonomies (Moldovan et al. 1999) and defines a two-level hierarchy of questions. The simplest method to classify questions is the use of a set of rules that map patterns of questions into question types. The patterns are expressed by means of regular expressions on the surface form. The identification of the answer type is usually performed by analyzing the interrogative terms of the question (Handbook of Natural Language Processing). Question Classification is typically done by using a set of patterns, a rule based approach. Another method of question classification is through a statistical based approach using machine learning.</li>
<li><strong>Query Generation</strong> - Once the question has been classified, the next process will be to select which of the words or entities will be used to retrieve the correct passage for the answer. This is accomplished by typically using keyword selection or again using a set of patterns.</li><br>

<p><strong>2.	Document or Passage Retrieval</strong></p>
<p style="text-indent:50px">Document or Passage Retrieval tasks are generally done through Information Retrieval systems rather than Natural Language Processing techniques as according to Gaizauskas (2004), using IR-Systems significantly reduces the time to search an entire document for the answer.  When IR-Systems are used, it is done typically with ranking methods.</p>

<p style="text-indent:50px">When using NLP techniques for Document or Passage Retrieval, passage retrieval is done through indexes. An example would be Litkowski (2000) who indexes with word pairs.</p>

<p><strong>3.	Answer Extraction</strong></p>
<p style="text-indent:50px">This component will complete the process of passage retrieval by corroborating the correct answer from the passages by either ranking them through the similarity in the text, ranking them based on the frequency of the words, ranking them according to rules already set in place, or ranking them through patterns.</p>

<p><strong>Corpus</strong></p>
<p style="text-indent:50px">For our corpus, we have chosen to pick a minimum of 50 questions in the field of diabetes. These questions will be chosen by gathering the top common results in search engines, websites, and for some variety, books. Currently, the corpus contains questions mainly from a book. An example from these set of questions is “What is diabetic coma?”  Respective answer pairings for the questions are also chosen for comparison and data training.</p>

<p><strong>Query</strong></p>
<p style="text-indent:50px">Following a previous study, (Towards a Medical Question-Answering System: a Feasibility Study; Jacquemart, Zweigenbaum) we shall elicit keywords by collecting named entities. In general taxonomies, these are names of people, disease, dates, etc. For our system, these will mainly be diseases, anatomical parts, signs, treatments, etc. For the purpose of reading a larger, more expansive input, we will implement common NLP tasks such as stemming and lemmatization for the input. We will also look into studying “stop word” elimination, for a more optimize querying.</p>

<p><strong>Evaluation</strong></p>
<p style="text-indent:50px">Since our study is to review the relevant advancements of NLP trends and technology, we shall conclude our study by analysing, reviewing, and comparing the results of a simple, traditional factoid based Question Answering system and a more complex, modern Question Answering system that uses neural networks.</p>

> V. Results and Discussions
<p style="text-indent:50px">We have approached the process of development following the traditional software development life cycle since we ought to develop first a working question answering system. Originally, we have looked for current platforms and frameworks to use for our development since apparently, the development of a question answering system from scratch is quite an overwhelming task. For the platforms that we have analysed, four stood out:</p>
<ol>
<li>OpenEphyra</li>
<li>QANUS</li>
<li>Quepy</li>
<li>Apache UIMA</li>
</ol>
<p style="text-indent:50px">Nevertheless, we chose to develop a question answering system from scratch as the four platforms and frameworks above proved to have their flaws. We have discovered that OpenEphyra’s documentations are archaic. On QANUS, we failed to deploy the system due to it not supporting the new windows 10, attempts were made to deploy the system on a Linux OS yet the lack of documentation for the technical side had us blindly rummaging for each of its components. Quepy has shown promised but we have soon learned that it restricts the addition of several components that we need. Apache UIMA, the framework that IBM Watson itself has used, has its own merits but the development, research, and deployment of our system using UIMA would take longer than the 4 months left for us to develop a working prototype.</p>
<p style="text-indent:50px">The platform analysis phase took us 2 weeks until we chose to develop our question answering system using Java and several libraries for Natural Language Processing.</p>
<h4>First Cycle of Development: Console Based QA</h4>
<br><center><img src="https://i.imgur.com/2EqKmEj.png"></center><br>
<p style="text-indent:50px">For the first cycle, it took us two months (September-October) to develop a working prototype. The system has successfully parsed and classified 68% of the 200 test questions; the 32% that failed the parsing component were relational questions. The following formula was used to score the accuracy:</p>
<br><center><<img src="https://i.imgur.com/Dz7ksE8.png"></center><br>
<p style="text-indent:50px">Though the success of its question processing component was adequate, the main pitfall of our developed system was its inadequacy to extract the answers. Text retrieval proved to be a daunting task, especially since we have to develop mathematical formulas and retrain the test questions along with the test answers.</p>
<h4>Second Cycle of Development: Browser Based QA</h4>
<br><center><img src="https://i.imgur.com/PbpASLO.png"></center><br>
<p style="text-indent:50px">The solution that we have found for our text retrieval problem posed from the previous development cycle was to develop the system on top of a search engine; which we soon learned that most question answering systems in fact, are built with search engines. The development started on November and the prototype was then deployed by November 29, a week before the final defense. For the search engine, we have developed it from scratch using Elasticsearch to handle the database. A PHP page was coded for the user interface, and for the question processing, NlpTools was used. Though the system successfully parses the questions and retrieves a correct answer, we have found that the scalability and modifiable entities using this architecture is too restricting. For example, we cannot extend the system by using machine learning methods or implement dynamic auto summarization of texts by adding further components.</p>

<h4>Third Cycle of Development: Apache UIMA Based QA</h4>
<br><center><img src="https://i.imgur.com/PgLBjSm.png"></center><br>
<p style="text-indent:50px">Since the development of the QA system conforming to the framework set by IBM Watson was too good to ignore, we have chosen to also develop the application along the background from October to present. For the question processing component, we are currently using Apache OpenNLP to train and classify the training questions and models using the Bayes theorem:</p>
<br><center><img src="https://i.imgur.com/Gv2ZgSF.png"></center><br>
<p align="center">Where A and B are events and P(B) ≠ 0.<br>
P(A) and P(B) are the probabilities of observing A and B without regard to each other.<br>
P(A | B), a conditional probability, is the probability of observing event A given that B is true.<br>
P(B | A) is the probability of observing event B given that A is true.</p>
<p style="text-indent:50px">For the text retrieval component, we will be using Apache Lucene and building on top of that, is a component using Apache Solr. Passage rankings will then be in hard coded Java.</p>
> VI.  Conclusions and Recommendations
<p style="text-indent:50px">Though we have succeeded in building a question answering system, the project is still a work in progress since we have yet to evaluate methods of traditional question answering systems using information retrieval and a more modern one, such as that of neural network model.
From a research perspective, we have succeeded in developing grammar parsing models using semantics for the first phase of development. We have also succeeded in creating working architectures for developing question answering systems for a console (which can easily be added a graphical user interface) and for browsers.
From these accomplishments, for the next term, we can then choose to branch our study to continue developing a question answering system using Apache UIMA; adding components such as automated text summarization of documents and stronger models for grammar parsing.
From the software we have created on our second cycle, we can also choose to pursue a path towards intelligent systems by extending it as an expert system; one that diagnoses medical problems using symptoms written in natural language format.
Lastly, we can also choose to pursue a research focused endeavor by removing our current models of information retrieval, as we replace it with memory networks sponsored by the Facebook Artificial Intelligence Research laboratory.</p>

> VII.  Appendices

<h3>Context Diagram</h3>
<br><center><img src="http://i.imgur.com/7ve3oo7.png"></center><br>
<h3>Data Flow Diagram</h3>
<br><center><img src="http://i.imgur.com/UjqO8Hb.png"></center><br>
<h3>Activity Diagram</h3>
<center><img src="http://i.imgur.com/sAxwaDO.jpg"></center>

<h3>Class Diagram</h3>
<center><img src="http://i.imgur.com/IrKfGjz.jpg"></center>

<h3>Communication Diagram</h3>
<center><img src="http://i.imgur.com/UTYOQg6.jpg"></center>

<h3>Component Diagram</h3>
<center><img src="http://i.imgur.com/VZdgbi5.png"></center>

<h3>Composite Structure Diagram</h3>

<center></center>

<h3>Deployment Diagram</h3>
<center><img src="http://i.imgur.com/nvXBtdN.jpg"></center><br>
<h3>Interaction Overview Diagram</h3>
<center><img src="http://i.imgur.com/iURO2pE.jpg"></center>

<h3>Object Diagram</h3>
<center><img src="http://i.imgur.com/fVVDHA0.jpg"></center>

<h3>Package Diagram</h3>
<center><img src="http://i.imgur.com/jkrKW9l.png"></center>
<h3>Sequence Diagram</h3>
<center><img src="http://i.imgur.com/YLaE5BJ.jpg"></center>

<h3>State Machine Diagram</h3>
<img src="http://i.imgur.com/XlExQYk.png">
<center></center>

<h3>Timing Diagram</h3>
<img src="http://i.imgur.com/eDzo7l0.png">
<center></center>

<h3>Use Case Diagram</h3>
<center><img src="http://i.imgur.com/BU8AuuN.jpg"></center>

<h3>Detailed Use Case Diagram</h3>
<center><img src="http://i.imgur.com/v0WgD2F.jpg"></center><br>
<center><img src="http://i.imgur.com/RIfGfeB.jpg"></center><br>
<center><img src="http://i.imgur.com/K03oZbg.jpg"></center><br>
<center><img src="http://i.imgur.com/JaoHjMd.jpg"></center><br>
<center><img src="http://i.imgur.com/a5ORQWU.jpg"></center><br>



> Sources
<li>Towards a Medical Question-Answering System: a Feasibility Study; Pierre Jacquemart, Pierre Zweigenbaum, from http://cluster.cis.drexel.edu:8080/sofia/resources/QA.Data/PDF/M_2003_Jacquemart_and_Zweigenbaum_Towards_a_Medical_Quesiton-Answering_System--A_Feasibility_Study-1144453120/M_2003_Jacquemart_and_Zweigenbaum_Towards_a_Medical_Quesiton-Answering_System--A_Feasibility_Study.pdf </li>
<li>International Journal of Web & Semantic Technology (IJWesT) Vol.4, No.4, October 2013 - Architecture of an Ontology-Based DomainSpecific Natural Language Question  Answering System, Athira P. M., Sreeja M. and P. C. Reghuraj Retrieved July 8, 2016 from http://airccse.org/journal/ijwest/papers/4413ijwest03.pdf</li>
<li>Information Search and Retrieval Graz University of Technology WS 2012/2013
 - New Trends in Automatic Question Answering, Christian Gailer, Stefan Kohl, Stephan Oberauer Retrieved July 8, 2016 from http://www.iicm.tugraz.at/0x811bc82b_0x0011c036</li>
<li>Harabagiu S and Moldovan D. Tutorial on open-domain textual question answering. In: Proc 19th
COLING, Taipei, Taiwan. 2002. </li>
<li> Moldovan D, Harabagiu S, and Surdeanu M. Performance issue and error analysis in an open-domain
question answering system. In: Proc 38 ACL, Philadelphia, PA. ACL, 2002. </li>
<li>AUTOMATED QUESTION-ANSWERING TECHNIQUES AND THE MEDICAL DOMAIN BY Andrea Andrenucci https://people.dsv.su.se/~andrea/QAapproachesHealthInf.pdf</li>
<li>The Structure and Performance  of anOpen-Domain QUestion Answering System - Moldovan et al from http://www.aclweb.org/anthology/P00-1071 </li>
<li>Information Retrieval for Question Answering a SIGIR 2004 Workshop - Robert Gaizauskas, Mark Hepple and Mark Greenwood from http://www.dcs.shef.ac.uk/~mark/nlp/pubs/gaizauskas_sigirforum_2004d.pdf</li>
<li>Unsupervised Sense Disambiguation Using Bilingual Probabilistic Models - Indrajit Bhattacharya, Lise Getoor, Yoshua Bengio from https://users.soe.ucsc.edu/~getoor/Papers/bhattacharya-acl04.pdf</li>
<li>https://en.wikipedia.org/wiki/UIMA</li>
<li>https://lucene.apache.org/solr/</li>
<li>http://lucene.apache.org/core/</li>
<li>http://stanfordnlp.github.io/CoreNLP/</li>
<li>http://alias-i.com/lingpipe/</li>
<li>https://opennlp.apache.org/</li>
<li>Implementation of Query Processor Using Automata and Natural Language Processing(http://www.ijsrp.org/research-paper-0513/ijsrp-p17113.pdf)<li>
